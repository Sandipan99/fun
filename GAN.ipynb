{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize pixel values\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Load data\n",
    "train_set = datasets.MNIST('mnist/', train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST('mnist/', train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for d in test_loader:\n",
    "    print(d[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(128, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(784, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "lr = 0.0002\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(1, 128)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▍                                                                               | 1/200 [00:45<2:29:56, 45.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████▏                                                          | 51/200 [38:49<2:03:12, 49.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████▍                                     | 101/200 [1:17:44<1:34:27, 57.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|██████████████████████████████████████████████████████████▉                   | 151/200 [1:59:22<40:24, 49.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 200/200 [2:39:27<00:00, 47.84s/it]\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "# Code adopted from https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        \n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        d_optimizer.zero_grad()\n",
    "        # Format batch\n",
    "        b_size = data[0].size(0)\n",
    "        real_data = data[0].squeeze(1).reshape(b_size, -1)\n",
    "        #print(real_data.shape)\n",
    "        #b_size = real_data.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float)\n",
    "        # Forward pass real batch through D\n",
    "        #print(real_data.shape)\n",
    "        output = D(real_data).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        #print(errD_real)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        \n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, 128)\n",
    "        # Generate fake image batch with G\n",
    "        fake = G(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        #print(fake.shape)\n",
    "        output = D(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        d_optimizer.step()\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        G.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = D(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        # Output training stats\n",
    "        #if i % 50 == 0:\n",
    "        #    print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "        #          % (epoch, epochs, i, len(train_dataloader),\n",
    "        #             errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        \n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "        \n",
    "    if epoch % 50 == 0:\n",
    "        torch.save(G, 'Generator_epoch_{}.pth'.format(epoch))\n",
    "        print('Model saved.')\n",
    "        # Check images created by generator\n",
    "        #if (iters % 500 == 0) or ((epoch == epochs-1) and (i == len(train_loader)-1)):\n",
    "        #    with torch.no_grad():\n",
    "        #        fake = G(fixed_noise).detach()\n",
    "        #        img = fake.reshape(28, 28)\n",
    "        #        img = img*0.5 + 0.5\n",
    "        #        plt.imshow(img.numpy())\n",
    "        \n",
    "        #iters+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_1 = torch.load('Generator_epoch_50.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x212606dda60>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fixed_noise = torch.rand(1, 128)\n",
    "fake = G_1(fixed_noise).detach()\n",
    "img = fake.reshape(28, 28)\n",
    "img = img*0.5 + 0.5\n",
    "plt.imshow(img.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
