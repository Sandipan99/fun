{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = []\n",
    "class_labels = []\n",
    "\n",
    "with open('Data/mnist_train_file.txt') as fs:\n",
    "    for line in fs:\n",
    "        data = list(map(int, line.strip().split(','))) \n",
    "        label = data[0]\n",
    "        datapoint = data[1:]\n",
    "        data_points.append(datapoint)\n",
    "        class_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "print(len(data_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_points[0]) ## 28 x 28 = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_dataset(Dataset):\n",
    "    def __init__(self, data_points, class_labels):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.data = data_points\n",
    "        self.labels = class_labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        # returns length of the dataset\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # retrieves an item of a given index\n",
    "        d = torch.FloatTensor(self.data[index])\n",
    "        l = torch.LongTensor([self.labels[index]])\n",
    "        return d,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = Mnist_dataset(data_points, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(128, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(784, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lr = 0.0002\n",
    "batch_size = 64\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(1, 128)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(mnist_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [1:40:01<00:00, 60.01s/it]\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "# Code adopted from https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        \n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        d_optimizer.zero_grad()\n",
    "        # Format batch\n",
    "        real_data = data[0]\n",
    "        b_size = real_data.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float)\n",
    "        # Forward pass real batch through D\n",
    "        #print(real_data.shape)\n",
    "        output = D(real_data).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        #print(errD_real)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        \n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, 128)\n",
    "        # Generate fake image batch with G\n",
    "        fake = G(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        #print(fake.shape)\n",
    "        output = D(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        d_optimizer.step()\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        G.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = D(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        # Output training stats\n",
    "        #if i % 50 == 0:\n",
    "        #    print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "        #          % (epoch, epochs, i, len(train_dataloader),\n",
    "        #             errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        \n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = torch.randn(1, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4892,  1.8759,  0.0971,  2.1452,  0.8780,  0.0964, -0.1903, -0.6248,\n",
       "          1.6668, -0.1235,  0.5641, -1.9917,  0.0731,  0.5406,  2.1486,  0.0496,\n",
       "          0.0515, -2.1160, -0.9580, -1.0199,  0.9723, -0.4940, -0.5654, -0.8745,\n",
       "         -1.7433,  0.1272,  0.0637,  1.8516,  0.4121,  2.6799,  0.9687, -0.3016,\n",
       "         -0.0905, -0.9719, -1.9745, -0.5294, -0.9834,  0.7691,  0.5797,  0.3526,\n",
       "          0.3010,  1.5277, -0.8418, -0.1558, -0.3043,  0.0795,  1.1885,  0.6338,\n",
       "         -1.1319, -0.4131, -1.9412,  1.7427,  0.8135, -0.2667,  1.9417, -0.4845,\n",
       "         -0.4865, -0.9703,  1.5727, -0.2267,  0.1825, -0.5286, -1.3106,  2.3532,\n",
       "         -0.1123,  0.6683, -0.9633, -1.6179, -0.4430,  0.5996, -0.6076,  0.2288,\n",
       "          1.2165, -1.2243, -1.3884, -2.3588,  1.0417, -0.5529, -0.6589, -0.5621,\n",
       "          1.0849,  1.3668, -0.0980,  0.2787, -0.1549, -0.0313,  0.9107,  0.5046,\n",
       "          0.7897, -2.1784,  1.4261, -0.2946, -0.4257, -0.2377,  0.0956, -0.5347,\n",
       "          0.1352,  0.5850, -0.3512,  0.3433,  0.7491,  0.0404,  0.0194,  0.4908,\n",
       "         -1.2830,  0.3247, -0.6880,  0.4571, -0.5366, -1.4412, -0.4951,  1.3115,\n",
       "          0.2607, -0.2104, -0.5946,  0.8132,  0.7760,  1.7549, -0.8724, -0.4973,\n",
       "         -1.2794, -0.4773,  1.5689, -0.6970, -1.7254, -0.8311,  0.4635, -0.0047]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = G(fixed_noise).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = fake.reshape(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x234138f52b0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.numpy(),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
