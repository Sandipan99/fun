{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Load data\n",
    "train_set = datasets.MNIST('mnist/', train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST('mnist/', train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"mnist.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for d in test_loader:\n",
    "    print(d[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(128, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(784, 256), # We flatten the image - 28 x 28 = 784\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 200\n",
    "lr = 0.0002\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(1, 128)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▍                                                                               | 1/200 [00:45<2:29:56, 45.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████▏                                                          | 51/200 [38:49<2:03:12, 49.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████▍                                     | 101/200 [1:17:44<1:34:27, 57.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|██████████████████████████████████████████████████████████▉                   | 151/200 [1:59:22<40:24, 49.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 200/200 [2:39:27<00:00, 47.84s/it]\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "# Code adopted from https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        \n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z))) same as minimizing BCE\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        d_optimizer.zero_grad()\n",
    "        b_size = data[0].size(0)\n",
    "        real_data = data[0].squeeze(1).reshape(b_size, -1) # real data\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float)\n",
    "        # Forward pass real batch through D\n",
    "        output = D(real_data).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, 128)\n",
    "        # Generate fake image batch with G\n",
    "        fake = G(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        #print(fake.shape)\n",
    "        output = D(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        errD_fake.backward()\n",
    "        \n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z))) or minimize -log(D(G(z)))\n",
    "        ###########################\n",
    "        G.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = D(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        # Update G\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "        \n",
    "    if epoch % 50 == 0:\n",
    "        torch.save(G, 'Generator_epoch_{}.pth'.format(epoch))\n",
    "        print('Model saved.')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_1 = torch.load('Generator_epoch_150.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16f3bf67460>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fixed_noise = torch.rand(1, 128)\n",
    "fake = G_1(fixed_noise).detach()\n",
    "img = fake.reshape(28, 28)\n",
    "plt.imshow(img.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
