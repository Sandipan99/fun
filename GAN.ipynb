{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Load data\n",
    "train_set = datasets.MNIST('mnist/', train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST('mnist/', train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"mnist.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for d in test_loader:\n",
    "    print(d[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(128, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(784, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "lr = 0.0002\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(1, 128)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▍                                                                               | 1/200 [00:45<2:29:56, 45.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████████████████▏                                                          | 51/200 [38:49<2:03:12, 49.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████▍                                     | 101/200 [1:17:44<1:34:27, 57.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|██████████████████████████████████████████████████████████▉                   | 151/200 [1:59:22<40:24, 49.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 200/200 [2:39:27<00:00, 47.84s/it]\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "# Code adopted from https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        \n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z))) same as minimizing BCE\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        d_optimizer.zero_grad()\n",
    "        # Format batch\n",
    "        b_size = data[0].size(0)\n",
    "        real_data = data[0].squeeze(1).reshape(b_size, -1)\n",
    "        #print(real_data.shape)\n",
    "        #b_size = real_data.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float)\n",
    "        # Forward pass real batch through D\n",
    "        #print(real_data.shape)\n",
    "        output = D(real_data).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        #print(errD_real)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        \n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, 128)\n",
    "        # Generate fake image batch with G\n",
    "        fake = G(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        #print(fake.shape)\n",
    "        output = D(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        d_optimizer.step()\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z))) or minimize -log(D(G(z)))\n",
    "        ###########################\n",
    "        G.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = D(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        # Output training stats\n",
    "        #if i % 50 == 0:\n",
    "        #    print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "        #          % (epoch, epochs, i, len(train_dataloader),\n",
    "        #             errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        \n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "        \n",
    "    if epoch % 50 == 0:\n",
    "        torch.save(G, 'Generator_epoch_{}.pth'.format(epoch))\n",
    "        print('Model saved.')\n",
    "        # Check images created by generator\n",
    "        #if (iters % 500 == 0) or ((epoch == epochs-1) and (i == len(train_loader)-1)):\n",
    "        #    with torch.no_grad():\n",
    "        #        fake = G(fixed_noise).detach()\n",
    "        #        img = fake.reshape(28, 28)\n",
    "        #        img = img*0.5 + 0.5\n",
    "        #        plt.imshow(img.numpy())\n",
    "        \n",
    "        #iters+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_1 = torch.load('Generator_epoch_150.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21260d63130>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fixed_noise = torch.rand(1, 128)\n",
    "fake = G_1(fixed_noise).detach()\n",
    "img = fake.reshape(28, 28)\n",
    "plt.imshow(img.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
